# ğŸ¨ Visual Matcher

AI-powered visual similarity search for product matching using CLIP embeddings
A full-stack application that leverages OpenAI's CLIP model to find visually similar products through intelligent image analysis and semantic understanding. Perfect for e-commerce, retail analytics, and product discovery platforms.

## âœ¨ Features

**ğŸ” Advanced Visual Search** - Find similar products using state-of-the-art CLIP embeddings
 **ğŸ·ï¸ Smart Metadata Filtering** - Combine visual similarity with brand and category filters
**âš¡ High Performance** - Optimized embedding computation and similarity matching
**ğŸ“¤ Image Upload** - Support for direct image uploads and URL-based queries
**ğŸ¯ Accurate Matching** - Leverages CLIP's multi-modal understanding for superior results
**ğŸ“Š Ranked Results** - Get similarity scores with each match for transparency
**ğŸ¨ Modern UI** - Clean, responsive interface built with React and Vite

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React     â”‚ â—„â”€â”€â”€â”€â–º â”‚   Express    â”‚ â—„â”€â”€â”€â”€â–º â”‚   Python    â”‚
â”‚   Frontend  â”‚  REST   â”‚   Backend    â”‚  API    â”‚   CLIP      â”‚
â”‚   (Vite)    â”‚         â”‚   (Node.js)  â”‚         â”‚   Module    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Embeddings  â”‚
                        â”‚   Storage    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

1. **Embedding Generation** - Python module encodes images into high-dimensional vectors using CLIP
2. **API Layer** - Express backend exposes endpoints for querying and indexing embeddings
3. **Similarity Search** - Cosine similarity computation identifies the closest visual matches
4. **Interactive UI** - React frontend provides seamless search and filtering experience

## ğŸš€ Quick Start

### Prerequisites

Ensure you have the following installed:

- **Node.js** (v16.x or higher)
- **Python** 3.8+
- **npm** or **yarn**
- *(Optional)* CUDA-capable GPU for faster processing

### Installation

```bash
# Clone the repository
git clone https://github.com/ashwinabey/visual-matcher.git
cd visual-matcher

# Install JavaScript dependencies
npm install

# Install Python dependencies
pip install -r requirements.txt
```

### Generate Embeddings

Process your product image dataset:

```bash
python clip_model.py --input_dir ./data/images --output ./embeddings.json
```

**Options:**
- `--input_dir` - Directory containing product images
- `--output` - Path for the embeddings output file
- `--batch_size` - Batch size for processing (default: 32)
- `--model` - CLIP model variant (default: ViT-B/32)

### Configuration

Create a `.env` file in the root directory:

```env
# Backend Configuration
PORT=3000
EMBEDDINGS_PATH=./embeddings.json
CORS_ORIGIN=http://localhost:5173

# Python Service
PYTHON_SERVICE_URL=http://localhost:5000

# Optional: Model Settings
CLIP_MODEL=ViT-B/32
SIMILARITY_THRESHOLD=0.75
```

Frontend configuration in `vite.config.js`:

```javascript
export default {
  server: {
    proxy: {
      '/api': 'http://localhost:3000'
    }
  }
}
```

### Running the Application

**Terminal 1 - Backend Server:**
```bash
npm run server
# or
node server.js
```

**Terminal 2 - Frontend Development Server:**
```bash
npm run dev
```

**Terminal 3 - Python Service (if separate):**
```bash
python app.py
```

Access the application at `http://localhost:5173`

## ğŸ“– Usage

### Basic Visual Search

1. **Upload an image** via the UI or drag-and-drop
2. **Click "Find Similar"** to initiate the search
3. **View results** ranked by visual similarity
4. **Apply filters** for brand, category, or price range

### API Endpoints

#### Search Similar Products
```bash
POST /api/search
Content-Type: multipart/form-data

{
  "image": <file>,
  "limit": 10,
  "filters": {
    "brand": "Nike",
    "category": "shoes"
  }
}
```

#### Get Product Embedding
```bash
GET /api/embedding/:productId
```

#### Index New Product
```bash
POST /api/index
Content-Type: application/json

{
  "productId": "prod_123",
  "imageUrl": "https://example.com/image.jpg",
  "metadata": {
    "brand": "Nike",
    "category": "shoes"
  }
}
```

## ğŸ“ Project Structure

```
visual-matcher/
â”œâ”€â”€ ğŸ“„ clip_model.py          # CLIP embedding generation
â”œâ”€â”€ ğŸ“„ server.js              # Express API server
â”œâ”€â”€ ğŸ“„ package.json           # Node dependencies
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“„ vite.config.js         # Vite configuration
â”œâ”€â”€ ğŸ“„ .env.example           # Environment variables template
â”œâ”€â”€ ğŸ“„ index.html             # HTML entry point
â”‚
â”œâ”€â”€ ğŸ“‚ src/                   # Frontend source
â”‚   â”œâ”€â”€ ğŸ“‚ components/        # React components
â”‚   â”‚   â”œâ”€â”€ SearchBar.jsx
â”‚   â”‚   â”œâ”€â”€ ProductCard.jsx
â”‚   â”‚   â”œâ”€â”€ FilterPanel.jsx
â”‚   â”‚   â””â”€â”€ ResultsGrid.jsx
â”‚   â”œâ”€â”€ ğŸ“‚ hooks/             # Custom React hooks
â”‚   â”œâ”€â”€ ğŸ“‚ services/          # API client services
â”‚   â”œâ”€â”€ ğŸ“‚ utils/             # Utility functions
â”‚   â”œâ”€â”€ App.jsx               # Main app component
â”‚   â””â”€â”€ main.jsx              # React entry point
â”‚
â”œâ”€â”€ ğŸ“‚ public/                # Static assets
â”œâ”€â”€ ğŸ“‚ data/                  # Sample datasets
â”œâ”€â”€ ğŸ“‚ models/                # Pre-trained model files
â””â”€â”€ ğŸ“‚ embeddings/            # Generated embeddings
```

## ğŸ”§ Advanced Configuration

### Using Different CLIP Models

```python
# In clip_model.py
AVAILABLE_MODELS = [
    "ViT-B/32",      # Fast, good for real-time
    "ViT-B/16",      # Better accuracy
    "ViT-L/14",      # Best accuracy, slower
]
```

### Performance Optimization

**For large datasets**, consider:
- Using approximate nearest neighbor libraries (FAISS, Annoy)
- Implementing embedding caching strategies
- Setting up a vector database (Pinecone, Weaviate)
- Enabling GPU acceleration for CLIP

Example with FAISS:
```python
import faiss
import numpy as np

# Build index
embeddings = np.array(embeddings_list).astype('float32')
index = faiss.IndexFlatIP(embeddings.shape[1])
index.add(embeddings)

# Search
distances, indices = index.search(query_embedding, k=10)
```

## ğŸ§ª Testing

```bash
# Run unit tests
npm test

# Run integration tests
npm run test:integration

# Test Python module
pytest tests/
```

## ğŸš¢ Deployment

### Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up -d
```

### Manual Deployment

1. Build the frontend:
   ```bash
   npm run build
   ```

2. Deploy backend to your platform (Heroku, AWS, etc.)
3. Set environment variables on production
4. Ensure embeddings file is accessible

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### Areas for Contribution

- ğŸ¯ **Algorithms** - Improve similarity metrics, implement FAISS/Annoy
- âš¡ **Performance** - Optimize embedding generation and search
- ğŸ¨ **UI/UX** - Enhance frontend design and user experience  
- ğŸ“š **Documentation** - Improve guides, add tutorials
- ğŸ§ª **Testing** - Add test coverage, CI/CD pipelines
- ğŸŒ **Features** - Multi-language support, batch processing

### Development Workflow

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes and commit (`git commit -m 'Add amazing feature'`)
4. Push to your branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Please ensure:
- Code follows existing style guidelines
- All tests pass
- Documentation is updated
- Commit messages are descriptive

## ğŸ“ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements

- **[OpenAI CLIP](https://github.com/openai/CLIP)** - The foundation of our visual understanding
- **[Vite](https://vitejs.dev/)** - Lightning-fast frontend tooling
- **[Express](https://expressjs.com/)** - Web framework for Node.js
- **[React](https://react.dev/)** - UI library





<div align="center">
  
**If you find this project helpful, please consider giving it a â­!**

Made with â¤ï¸ by [Shreya Kumari]((https://github.com/shreyakumari99))

</div>
